% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RLT.r
\name{RLT}
\alias{RLT}
\title{\preformatted{            Reinforcement Learning Trees
}}
\usage{
RLT(
  x,
  y,
  censor = NULL,
  model = NULL,
  reinforcement = FALSE,
  ntrees = if (reinforcement) 100 else 500,
  mtry = max(1, as.integer(ncol(x)/3)),
  nmin = max(1, as.integer(log(nrow(x)))),
  alpha = 0,
  split.gen = "random",
  split.rule = NULL,
  nsplit = 1,
  replacement = TRUE,
  resample.prob = if (replacement) 1 else 0.85,
  obs.w = NULL,
  var.w = NULL,
  importance = FALSE,
  track.obs = FALSE,
  ObsTrack = NaN,
  RLT.control = list(RLT = FALSE),
  seed = NaN,
  ncores = 1,
  verbose = 0,
  ...
)
}
\arguments{
\item{x}{A \code{matrix} or \code{data.frame} of features}

\item{y}{Response variable. a \code{numeric}/\code{factor} vector.}

\item{censor}{The censoring indicator if survival model is used.}

\item{model}{The model type: \code{"regression"}, \code{"classification"}
or \code{"survival"}.}

\item{reinforcement}{Should reinforcement splitting rule be used. Default
is \code{"FALSE"}, i.e., regular random forests. When it
is activated, embedded model tuning parameters are
automatically chosen. They can also be specified in
\code{RLT.control}.}

\item{ntrees}{Number of trees, \code{ntrees = 100} if reinforcement is
used and \code{ntrees = 1000} otherwise.}

\item{mtry}{Number of randomly selected variables used at each
internal node.}

\item{nmin}{Terminal node size. Splitting will stop when the
internal node size is less than twice of \code{nmin}. This
is equivalent to setting \code{nodesize} = 2*\code{nmin} in the
\code{randomForest} package.}

\item{alpha}{Minimum number of observations required for each
child node as a portion of the parent node. Must be
within \verb{[0, 0.5)}. When \code{alpha} $> 0$ and \code{split.gen}
is \code{rank} or \code{best}, this will force each child node
to contain at least \eqn{\max(\texttt{nmin}, \alpha \times N_A)}
number of number of observations, where $N_A$ is the
sample size at the current internal node. This is
mainly for theoritical concern.}

\item{split.gen}{How the cutting points are generated: \code{"random"},
\code{"rank"} or \code{"best"}. \code{"random"} performs random
cutting point and does not take \code{alpha} into
consideration. \code{"rank"} could be more effective when
there are a large number of ties. It can also be used
to guarantee child node size if \code{alpha} > 0. \code{"best"}
finds the best cutting point, and can be cominbed with
\code{alpha} too.}

\item{split.rule}{Splitting rule for comparison:
\item{regression}{\code{"var"} for variance reduction}
\item{survival}{\code{"logrank"}, \code{"suplogrank"},
\code{"LL"} and \code{"penLL"}}
\item{classification}{\code{"gini"}}}

\item{nsplit}{Number of random cutting points to compare for each
variable at an internal node.}

\item{replacement}{Whether the in-bag samples are sampled with
replacement.}

\item{resample.prob}{Proportion of in-bag samples.}

\item{obs.w}{Observation weights}

\item{var.w}{Variable weights. When \code{"split.rule"} is not
\code{"penLL"}, this performs weighted sample of \code{"mtry"}
variables to select the splitting variable. Otherwise
this is treated as the penalty.}

\item{importance}{Should importance measures be calculated}

\item{track.obs}{Track which terminal node the observation belongs to.
The fitted object will return \code{"ObsTrack"} as the
indicator/counts of in-bag data.}

\item{ObsTrack}{Pre-specified matrix for in-bag data indicator/count
matrix. It will not be used if it contains any
negative value. This is an experimental feature, try
at your own risk.}

\item{RLT.control}{A list of tuning parameters for embedded model in
reinforcement splitting rule. See \code{RLT.control}.}

\item{seed}{Random seed using the \verb{Xoshiro256+} generator.}

\item{ncores}{Number of cores. Default is 1.}

\item{verbose}{Whether fitting should be printed.}

\item{...}{Additional arguments.}
}
\value{
A \code{RLT} object, constructed as a list consisting

\item{FittedForest}{Fitted tree structures}
\item{VarImp}{Variable importance measures, if \code{importance = TRUE}}
\item{Prediction}{In-bag prediction values}
\item{OOBPrediction}{Out-of-bag prediction values}
\item{ObsTrack}{An indicator matrix for whether each observation is used in
each fitted tree}
}
\description{
\preformatted{      Fit models for regression, classification and 
                   survival analysis using reinforced splitting rules.
                   The model reduces to regular random forests if 
                   reinforcement is turned off.
}
}
\references{
Zhu, R., Zeng, D., & Kosorok, M. R. (2015) "Reinforcement Learning Trees." Journal of the American Statistical Association. 110(512), 1770-1784.

Zhu, R., & Kosorok, M. R. (2012). "Recursively Imputed Survival Trees." Journal of the American Statistical Association, 107(497), 331-340.
}
